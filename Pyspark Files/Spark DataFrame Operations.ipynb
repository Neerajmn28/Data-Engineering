{"cells":[{"cell_type":"code","execution_count":2,"id":"fa5fbfdf","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["25/07/10 14:13:45 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n","                                                                                \r"]},{"name":"stdout","output_type":"stream","text":["+---+-------+---+\n","| id|   name|age|\n","+---+-------+---+\n","|  1|  Alice| 25|\n","|  2|    Bob| 30|\n","|  3|Charlie| 35|\n","+---+-------+---+\n","\n"]}],"source":["from pyspark.sql.types import StructType,StructField, IntegerType, StringType\n","\n","# create Spark Session\n","\n","spark = SparkSession.builder.appName('DateFrameOps').getOrCreate()\n","\n","# sample data\n","data = [\n","    (1,'Alice',25),\n","    (2,'Bob',30),\n","    (3,'Charlie',35)\n","]\n","\n","# define schema\n","schema = StructType([\n","    StructField('id', IntegerType(), False),\n","    StructField('name', StringType(), False),\n","    StructField('age',IntegerType(), False)\n","])\n","\n","# create DataFrame\n","df = spark.createDataFrame(data, schema)\n","\n","# show data\n","df.show()"]},{"cell_type":"code","execution_count":3,"id":"b5fcae0c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+-----+---+\n","| id| name|age|\n","+---+-----+---+\n","|  1|Alice| 25|\n","|  2|  Bob| 30|\n","+---+-----+---+\n","only showing top 2 rows\n","\n"]}],"source":["df.show(2)"]},{"cell_type":"code","execution_count":4,"id":"2993003c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- id: integer (nullable = false)\n"," |-- name: string (nullable = false)\n"," |-- age: integer (nullable = false)\n","\n"]}],"source":["df.printSchema()"]},{"cell_type":"code","execution_count":5,"id":"3399680f","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[Stage 6:>                                                          (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+-------+---+-------+----+\n","|summary| id|   name| age|\n","+-------+---+-------+----+\n","|  count|  3|      3|   3|\n","|   mean|2.0|   NULL|30.0|\n","| stddev|1.0|   NULL| 5.0|\n","|    min|  1|  Alice|  25|\n","|    max|  3|Charlie|  35|\n","+-------+---+-------+----+\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["df.describe().show()"]},{"cell_type":"code","execution_count":6,"id":"02ca3119","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+---+\n","|   name|age|\n","+-------+---+\n","|  Alice| 25|\n","|    Bob| 30|\n","|Charlie| 35|\n","+-------+---+\n","\n"]}],"source":["# select and filtering data use cases\n","\n","df.select('name','age').show()"]},{"cell_type":"code","execution_count":7,"id":"62a1a2f3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+-------+---+\n","| id|   name|age|\n","+---+-------+---+\n","|  2|    Bob| 30|\n","|  3|Charlie| 35|\n","+---+-------+---+\n","\n"]}],"source":["df.filter(df.age>25).show()"]},{"cell_type":"code","execution_count":8,"id":"f3443606","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+-----+---+\n","| id| name|age|\n","+---+-----+---+\n","|  1|Alice| 25|\n","+---+-----+---+\n","\n"]}],"source":["df.where(df.name=='Alice').show()"]},{"cell_type":"code","execution_count":9,"id":"1e98218e","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 13:>                                                         (0 + 1) / 2]\r","\r","[Stage 13:=============================>                            (1 + 1) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["+---+-------+---+\n","| id|   name|age|\n","+---+-------+---+\n","|  1|  Alice| 25|\n","|  2|    Bob| 30|\n","|  3|Charlie| 35|\n","+---+-------+---+\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["df.distinct().show()"]},{"cell_type":"code","execution_count":10,"id":"d44d53c7","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 16:=============================>                            (1 + 1) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["+---+-------+---+\n","| id|   name|age|\n","+---+-------+---+\n","|  1|  Alice| 25|\n","|  2|    Bob| 30|\n","|  3|Charlie| 35|\n","+---+-------+---+\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# Sorting and Ordering\n","df.orderBy('age').show()"]},{"cell_type":"code","execution_count":11,"id":"2a049f30","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+-------+---+\n","| id|   name|age|\n","+---+-------+---+\n","|  3|Charlie| 35|\n","|  2|    Bob| 30|\n","|  1|  Alice| 25|\n","+---+-------+---+\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","[Stage 17:=============================>                            (1 + 1) / 2]\r","\r","                                                                                \r"]}],"source":["df.orderBy(df.age.desc()).show()"]},{"cell_type":"code","execution_count":12,"id":"bf7917e0","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+-------+---+-------+\n","| id|   name|age|new_age|\n","+---+-------+---+-------+\n","|  1|  Alice| 25|     30|\n","|  2|    Bob| 30|     35|\n","|  3|Charlie| 35|     40|\n","+---+-------+---+-------+\n","\n"]}],"source":["# adding or dropping columns\n","\n","df.withColumn('new_age',df.age+5).show()"]},{"cell_type":"code","execution_count":13,"id":"c43cb004","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 20:=============================>                            (1 + 1) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["+-------+-----+\n","|   name|count|\n","+-------+-----+\n","|Charlie|    1|\n","|    Bob|    1|\n","|  Alice|    1|\n","+-------+-----+\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# aggregation and grouping\n","\n","df.groupBy('name').count().show()"]},{"cell_type":"code","execution_count":14,"id":"04436033","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------+\n","|avg(age)|\n","+--------+\n","|    30.0|\n","+--------+\n","\n"]}],"source":["df.agg({'age':'avg'}).show()"]},{"cell_type":"code","execution_count":15,"id":"bd03a644","metadata":{},"outputs":[],"source":["data_2 = [(\n","1,'usa'),(2,'uk'),(3,'india')]\n","\n","\n","schema_2 = StructType(\n","    [StructField('id',IntegerType(),True),\n","    StructField('country',StringType(),True)]\n",")"]},{"cell_type":"code","execution_count":16,"id":"980dbe82","metadata":{},"outputs":[],"source":["df_2 = spark.createDataFrame(data_2,schema_2)"]},{"cell_type":"code","execution_count":17,"id":"cd22b032","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 27:>                                                         (0 + 2) / 2]\r"]},{"name":"stdout","output_type":"stream","text":["+---+-------+---+-------+\n","| id|   name|age|country|\n","+---+-------+---+-------+\n","|  1|  Alice| 25|    usa|\n","|  2|    Bob| 30|     uk|\n","|  3|Charlie| 35|  india|\n","+---+-------+---+-------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","[Stage 30:>                                                         (0 + 1) / 1]\r","\r","                                                                                \r"]}],"source":["df.join(df_2,'id').show()"]},{"cell_type":"code","execution_count":18,"id":"accde081","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+-------+---+\n","| id|   name|age|\n","+---+-------+---+\n","|  1|  Alice| 25|\n","|  2|    Bob| 30|\n","|  3|Charlie| 35|\n","+---+-------+---+\n","\n"]}],"source":["df.show()"]},{"cell_type":"code","execution_count":20,"id":"6cfd9d26","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+------------+---------+-----------+------+---------+\n","| id|        name|     city|       date|amount|is_active|\n","+---+------------+---------+-----------+------+---------+\n","|  1|    john doe|Bangalore| 2023-01-15|152.75|     True|\n","|  2|  jane smith|    delhi| 2023-05-20| 89.50|    False|\n","|  3|RObert Brown|   Mumbai|invalidDate|  NULL|      yes|\n","|  4|  Lind White|  Kolkata| 2023-02-29|   NaN|        1|\n","|  5|  Mike Green|  Chennai| 2023-08-29|   Nan|        1|\n","|  6|  Sarah Blue| Hyderbad|InvalidDate|300.40|       No|\n","+---+------------+---------+-----------+------+---------+\n","\n"]}],"source":["data = [\n","    (1,'john doe','Bangalore','2023-01-15','152.75','True'),\n","    (2,'jane smith','delhi','2023-05-20','89.50','False'),\n","    (3,'RObert Brown','Mumbai','invalidDate',None,'yes'),\n","    (4,'Lind White','Kolkata','2023-02-29','NaN','1'),\n","    (5,'Mike Green','Chennai','2023-08-29','Nan','1'),\n","    (6,'Sarah Blue','Hyderbad','InvalidDate','300.40','No')\n","]\n","\n","\n","Columns = ['id','name','city','date','amount','is_active']\n","\n","\n","df = spark.createDataFrame(data, schema = Columns)\n","\n","# Show the DataFrame\n","df.show()"]},{"cell_type":"code","execution_count":21,"id":"d3578ba0","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- id: long (nullable = true)\n"," |-- name: string (nullable = true)\n"," |-- city: string (nullable = true)\n"," |-- date: string (nullable = true)\n"," |-- amount: string (nullable = true)\n"," |-- is_active: string (nullable = true)\n","\n"]}],"source":["df.printSchema()"]},{"cell_type":"code","execution_count":null,"id":"737a0c2b","metadata":{},"outputs":[],"source":["# handle Integer Column"]},{"cell_type":"code","execution_count":22,"id":"add02c4e","metadata":{},"outputs":[{"data":{"text/plain":["Column<'id'>"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["df.id"]},{"cell_type":"code","execution_count":23,"id":"53540f20","metadata":{},"outputs":[{"data":{"text/plain":["Column<'id'>"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["df['id']"]},{"cell_type":"code","execution_count":24,"id":"af97cbc8","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----------+--------+-----------+------+---------+\n","| id|      name|    city|       date|amount|is_active|\n","+---+----------+--------+-----------+------+---------+\n","|  4|Lind White| Kolkata| 2023-02-29|   NaN|        1|\n","|  5|Mike Green| Chennai| 2023-08-29|   Nan|        1|\n","|  6|Sarah Blue|Hyderbad|InvalidDate|300.40|       No|\n","+---+----------+--------+-----------+------+---------+\n","\n"]}],"source":["df.filter(df.id>3).show()"]},{"cell_type":"code","execution_count":25,"id":"b1b992b3","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+------------+---------+-----------+------+---------+---------+\n","| id|        name|     city|       date|amount|is_active|id_double|\n","+---+------------+---------+-----------+------+---------+---------+\n","|  1|    john doe|Bangalore| 2023-01-15|152.75|     True|        2|\n","|  2|  jane smith|    delhi| 2023-05-20| 89.50|    False|        4|\n","|  3|RObert Brown|   Mumbai|invalidDate|  NULL|      yes|        6|\n","|  4|  Lind White|  Kolkata| 2023-02-29|   NaN|        1|        8|\n","|  5|  Mike Green|  Chennai| 2023-08-29|   Nan|        1|       10|\n","|  6|  Sarah Blue| Hyderbad|InvalidDate|300.40|       No|       12|\n","+---+------------+---------+-----------+------+---------+---------+\n","\n"]}],"source":["df.withColumn('id_double',df.id*2).show()"]},{"cell_type":"code","execution_count":30,"id":"1a0c749e","metadata":{},"outputs":[],"source":["from pyspark.sql.types import IntegerType\n","from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n","from pyspark.sql.functions import col\n","\n","\n","df = df.withColumn('id', col('id').cast(IntegerType()))"]},{"cell_type":"code","execution_count":31,"id":"30b8bdfe","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+------------+---------+-----------+------+---------+\n","| id|        name|     city|       date|amount|is_active|\n","+---+------------+---------+-----------+------+---------+\n","|  1|    john doe|Bangalore| 2023-01-15|152.75|     True|\n","|  2|  jane smith|    delhi| 2023-05-20| 89.50|    False|\n","|  3|RObert Brown|   Mumbai|invalidDate|  NULL|      yes|\n","|  4|  Lind White|  Kolkata| 2023-02-29|   NaN|        1|\n","|  5|  Mike Green|  Chennai| 2023-08-29|   Nan|        1|\n","|  6|  Sarah Blue| Hyderbad|InvalidDate|300.40|       No|\n","+---+------------+---------+-----------+------+---------+\n","\n"]}],"source":["df.show()"]},{"cell_type":"code","execution_count":32,"id":"f88d877a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- id: integer (nullable = true)\n"," |-- name: string (nullable = true)\n"," |-- city: string (nullable = true)\n"," |-- date: string (nullable = true)\n"," |-- amount: string (nullable = true)\n"," |-- is_active: string (nullable = true)\n","\n"]}],"source":["df.printSchema()"]},{"cell_type":"code","execution_count":33,"id":"cb140916","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+------------+---------+-----------+------+---------+------------+\n","| id|        name|     city|       date|amount|is_active|  name_upper|\n","+---+------------+---------+-----------+------+---------+------------+\n","|  1|    john doe|Bangalore| 2023-01-15|152.75|     True|    JOHN DOE|\n","|  2|  jane smith|    delhi| 2023-05-20| 89.50|    False|  JANE SMITH|\n","|  3|RObert Brown|   Mumbai|invalidDate|  NULL|      yes|ROBERT BROWN|\n","|  4|  Lind White|  Kolkata| 2023-02-29|   NaN|        1|  LIND WHITE|\n","|  5|  Mike Green|  Chennai| 2023-08-29|   Nan|        1|  MIKE GREEN|\n","|  6|  Sarah Blue| Hyderbad|InvalidDate|300.40|       No|  SARAH BLUE|\n","+---+------------+---------+-----------+------+---------+------------+\n","\n"]}],"source":["# String Columns\n","\n","from pyspark.sql.functions import *\n","\n","df = df.withColumn('name_upper',upper(df.name))\n","df.show()"]},{"cell_type":"code","execution_count":35,"id":"e666cff2","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+------------+---------+-----------+------+---------+------------+------------+\n","| id|        name|     city|       date|amount|is_active|  name_upper|  name_lower|\n","+---+------------+---------+-----------+------+---------+------------+------------+\n","|  1|    john doe|Bangalore| 2023-01-15|152.75|     True|    JOHN DOE|    john doe|\n","|  2|  jane smith|    delhi| 2023-05-20| 89.50|    False|  JANE SMITH|  jane smith|\n","|  3|RObert Brown|   Mumbai|invalidDate|  NULL|      yes|ROBERT BROWN|robert brown|\n","|  4|  Lind White|  Kolkata| 2023-02-29|   NaN|        1|  LIND WHITE|  lind white|\n","|  5|  Mike Green|  Chennai| 2023-08-29|   Nan|        1|  MIKE GREEN|  mike green|\n","|  6|  Sarah Blue| Hyderbad|InvalidDate|300.40|       No|  SARAH BLUE|  sarah blue|\n","+---+------------+---------+-----------+------+---------+------------+------------+\n","\n"]}],"source":["# Lower case\n","\n","df = df.withColumn('name_lower',lower(df.name))\n","df.show()"]},{"cell_type":"code","execution_count":37,"id":"2ecf770d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+--------+---------+----------+------+---------+----------+----------+\n","| id|    name|     city|      date|amount|is_active|name_upper|name_lower|\n","+---+--------+---------+----------+------+---------+----------+----------+\n","|  1|john doe|Bangalore|2023-01-15|152.75|     True|  JOHN DOE|  john doe|\n","+---+--------+---------+----------+------+---------+----------+----------+\n","\n"]}],"source":["df.filter(df.city.startswith('B')).show()"]},{"cell_type":"code","execution_count":38,"id":"48756472","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- id: integer (nullable = true)\n"," |-- name: string (nullable = true)\n"," |-- city: string (nullable = true)\n"," |-- date: string (nullable = true)\n"," |-- amount: float (nullable = true)\n"," |-- is_active: string (nullable = true)\n"," |-- name_upper: string (nullable = true)\n"," |-- name_lower: string (nullable = true)\n","\n","+---+------------+---------+-----------+------+---------+------------+------------+\n","| id|        name|     city|       date|amount|is_active|  name_upper|  name_lower|\n","+---+------------+---------+-----------+------+---------+------------+------------+\n","|  1|    john doe|Bangalore| 2023-01-15|152.75|     True|    JOHN DOE|    john doe|\n","|  2|  jane smith|    delhi| 2023-05-20|  89.5|    False|  JANE SMITH|  jane smith|\n","|  3|RObert Brown|   Mumbai|invalidDate|  NULL|      yes|ROBERT BROWN|robert brown|\n","|  4|  Lind White|  Kolkata| 2023-02-29|   NaN|        1|  LIND WHITE|  lind white|\n","|  5|  Mike Green|  Chennai| 2023-08-29|   NaN|        1|  MIKE GREEN|  mike green|\n","|  6|  Sarah Blue| Hyderbad|InvalidDate| 300.4|       No|  SARAH BLUE|  sarah blue|\n","+---+------------+---------+-----------+------+---------+------------+------------+\n","\n"]}],"source":["df = df.withColumn('amount',col('amount').cast('float'))\n","df.printSchema()\n","df.show()"]},{"cell_type":"code","execution_count":40,"id":"317ce14b","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+------------+---------+-----------+------+---------+------------+------------+\n","| id|        name|     city|       date|amount|is_active|  name_upper|  name_lower|\n","+---+------------+---------+-----------+------+---------+------------+------------+\n","|  1|    john doe|Bangalore| 2023-01-15|152.75|     True|    JOHN DOE|    john doe|\n","|  2|  jane smith|    delhi| 2023-05-20|  89.5|    False|  JANE SMITH|  jane smith|\n","|  3|RObert Brown|   Mumbai|invalidDate|   0.0|      yes|ROBERT BROWN|robert brown|\n","|  4|  Lind White|  Kolkata| 2023-02-29|   0.0|        1|  LIND WHITE|  lind white|\n","|  5|  Mike Green|  Chennai| 2023-08-29|   0.0|        1|  MIKE GREEN|  mike green|\n","|  6|  Sarah Blue| Hyderbad|InvalidDate| 300.4|       No|  SARAH BLUE|  sarah blue|\n","+---+------------+---------+-----------+------+---------+------------+------------+\n","\n"]}],"source":["df_filled = df.fillna({'amount':0})\n","df_filled.show()"]},{"cell_type":"code","execution_count":null,"id":"4b583abe","metadata":{},"outputs":[],"source":["# Handle Date Column"]},{"cell_type":"code","execution_count":41,"id":"eba57e0b","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["25/07/10 16:14:39 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"]}],"source":["from pyspark.sql import SparkSession\n","\n","\n","# Intialize Spark session\n","spark = SparkSession.builder \\\n",".appName('Handling Dates in Pyspark') \\\n",".getOrCreate()"]},{"cell_type":"code","execution_count":43,"id":"39acc234","metadata":{},"outputs":[],"source":["# Sending the Data to hdfs via Notebook\n","\n","# Create a Csv File\n","csv_data = '''id,date_iso,date_dmy,date_mdy,timestamp\n","1,2025-07-08,08/07/2025,07/08/2025,2025-07-08 14:30:00\n","2,2024-12-25,25/12/2024,12/25/2024,2024-12-25 09:00:00\n","3,2023-01-01,01/01/2023,01/01/2023,2023-01-01 00:00:00\n","4,2022-11-15,15/11/2022,11/15/2022,2022-11-15 18:45:00\n","'''\n","\n","# Save the Csv file\n","with open('dates_data.csv','w') as f:\n","    f.write(csv_data)"]},{"cell_type":"code","execution_count":44,"id":"da7300e3","metadata":{},"outputs":[],"source":["!hadoop fs -put dates_data.csv /data/dates_data.csv"]},{"cell_type":"code","execution_count":46,"id":"835f9379","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["\r","[Stage 53:>                                                         (0 + 1) / 1]\r"]},{"name":"stdout","output_type":"stream","text":["+---+----------+----------+----------+-------------------+\n","|id |date_iso  |date_dmy  |date_mdy  |timestamp          |\n","+---+----------+----------+----------+-------------------+\n","|1  |2025-07-08|08/07/2025|07/08/2025|2025-07-08 14:30:00|\n","|2  |2024-12-25|25/12/2024|12/25/2024|2024-12-25 09:00:00|\n","|3  |2023-01-01|01/01/2023|01/01/2023|2023-01-01 00:00:00|\n","|4  |2022-11-15|15/11/2022|11/15/2022|2022-11-15 18:45:00|\n","+---+----------+----------+----------+-------------------+\n","\n"]},{"name":"stderr","output_type":"stream","text":["\r","                                                                                \r"]}],"source":["# DDl String for the schema\n","\n","ddl_schema = '''\n","id INT,\n","date_iso STRING,\n","date_dmy STRING,\n","date_mdy STRING,\n","timestamp STRING'''\n","\n","\n","from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n","\n","# read the csv file into a datafram\n","df_file = spark.read.option('header',True).schema(ddl_schema).csv('/data/dates_data.csv')\n","\n","# Show the DataFrame\n","df_file.show(truncate = False)"]},{"cell_type":"code","execution_count":47,"id":"5573398a","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- id: integer (nullable = true)\n"," |-- date_iso: string (nullable = true)\n"," |-- date_dmy: string (nullable = true)\n"," |-- date_mdy: string (nullable = true)\n"," |-- timestamp: string (nullable = true)\n","\n"]}],"source":["df_file.printSchema()"]},{"cell_type":"code","execution_count":49,"id":"622e9e15","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----------+----------+----------+-------------------+\n","|id |date_iso  |date_dmy  |date_mdy  |timestamp          |\n","+---+----------+----------+----------+-------------------+\n","|1  |2025-07-08|08/07/2025|07/08/2025|2025-07-08 14:30:00|\n","|2  |2024-12-25|25/12/2024|12/25/2024|2024-12-25 09:00:00|\n","|3  |2023-01-01|01/01/2023|01/01/2023|2023-01-01 00:00:00|\n","|4  |2022-11-15|15/11/2022|11/15/2022|2022-11-15 18:45:00|\n","+---+----------+----------+----------+-------------------+\n","\n"]}],"source":["data = [\n","    (1,'2025-07-08','08/07/2025','07/08/2025','2025-07-08 14:30:00'),\n","    (2,'2024-12-25','25/12/2024','12/25/2024','2024-12-25 09:00:00'),\n","    (3,'2023-01-01','01/01/2023','01/01/2023','2023-01-01 00:00:00'),\n","    (4,'2022-11-15','15/11/2022','11/15/2022','2022-11-15 18:45:00')\n","]\n","\n","columns = ['id','date_iso','date_dmy','date_mdy','timestamp']\n","\n","# create DataFrame\n","df = spark.createDataFrame(data, schema = columns)\n","\n","# show the DataFrame\n","df.show(truncate=False)"]},{"cell_type":"code","execution_count":50,"id":"adea5c8c","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- id: long (nullable = true)\n"," |-- date_iso: string (nullable = true)\n"," |-- date_dmy: string (nullable = true)\n"," |-- date_mdy: string (nullable = true)\n"," |-- timestamp: string (nullable = true)\n","\n"]}],"source":["df.printSchema()"]},{"cell_type":"code","execution_count":52,"id":"d90c6551","metadata":{},"outputs":[],"source":["from pyspark.sql.functions import to_date\n","\n","df = df\\\n",".withColumn('parsed_date_iso',to_date(df.date_iso, 'yyyy-MM-dd'))\\\n",".withColumn('parsed_date_dmy',to_date(df.date_dmy, 'dd/MM/yyyy'))\\\n",".withColumn('parsed_date_mdy',to_date(df.date_mdy,'MM/dd/yyyy'))"]},{"cell_type":"code","execution_count":53,"id":"872a94e9","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----------+----------+----------+-------------------+---------------+---------------+---------------+\n","|id |date_iso  |date_dmy  |date_mdy  |timestamp          |parsed_date_iso|parsed_date_dmy|parsed_date_mdy|\n","+---+----------+----------+----------+-------------------+---------------+---------------+---------------+\n","|1  |2025-07-08|08/07/2025|07/08/2025|2025-07-08 14:30:00|2025-07-08     |2025-07-08     |2025-07-08     |\n","|2  |2024-12-25|25/12/2024|12/25/2024|2024-12-25 09:00:00|2024-12-25     |2024-12-25     |2024-12-25     |\n","|3  |2023-01-01|01/01/2023|01/01/2023|2023-01-01 00:00:00|2023-01-01     |2023-01-01     |2023-01-01     |\n","|4  |2022-11-15|15/11/2022|11/15/2022|2022-11-15 18:45:00|2022-11-15     |2022-11-15     |2022-11-15     |\n","+---+----------+----------+----------+-------------------+---------------+---------------+---------------+\n","\n"]}],"source":["df.show(truncate=False)"]},{"cell_type":"code","execution_count":54,"id":"bc5650cc","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---+----------+----------+----------+-------------------+---------------+---------------+---------------+-------------------+\n","| id|  date_iso|  date_dmy|  date_mdy|          timestamp|parsed_date_iso|parsed_date_dmy|parsed_date_mdy|   parsed_timestamp|\n","+---+----------+----------+----------+-------------------+---------------+---------------+---------------+-------------------+\n","|  1|2025-07-08|08/07/2025|07/08/2025|2025-07-08 14:30:00|     2025-07-08|     2025-07-08|     2025-07-08|2025-07-08 14:30:00|\n","|  2|2024-12-25|25/12/2024|12/25/2024|2024-12-25 09:00:00|     2024-12-25|     2024-12-25|     2024-12-25|2024-12-25 09:00:00|\n","|  3|2023-01-01|01/01/2023|01/01/2023|2023-01-01 00:00:00|     2023-01-01|     2023-01-01|     2023-01-01|2023-01-01 00:00:00|\n","|  4|2022-11-15|15/11/2022|11/15/2022|2022-11-15 18:45:00|     2022-11-15|     2022-11-15|     2022-11-15|2022-11-15 18:45:00|\n","+---+----------+----------+----------+-------------------+---------------+---------------+---------------+-------------------+\n","\n","root\n"," |-- id: long (nullable = true)\n"," |-- date_iso: string (nullable = true)\n"," |-- date_dmy: string (nullable = true)\n"," |-- date_mdy: string (nullable = true)\n"," |-- timestamp: string (nullable = true)\n"," |-- parsed_date_iso: date (nullable = true)\n"," |-- parsed_date_dmy: date (nullable = true)\n"," |-- parsed_date_mdy: date (nullable = true)\n"," |-- parsed_timestamp: timestamp (nullable = true)\n","\n"]}],"source":["# Timestamp\n","\n","from pyspark.sql.functions import to_timestamp, year, month, dayofmonth, hour, minute\n","\n","df = df.withColumn('parsed_timestamp',to_timestamp(df.timestamp, 'yyyy-MM-dd HH:mm:ss'))\n","df.show()\n","df.printSchema()"]},{"cell_type":"code","execution_count":57,"id":"66e6423d","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["+---------------+---------------+---------------+\n","|parsed_date_mdy|parsed_date_iso|days_difference|\n","+---------------+---------------+---------------+\n","|2025-07-08     |2025-07-08     |0              |\n","|2024-12-25     |2024-12-25     |0              |\n","|2023-01-01     |2023-01-01     |0              |\n","|2022-11-15     |2022-11-15     |0              |\n","+---------------+---------------+---------------+\n","\n"]}],"source":["from pyspark.sql.functions import datediff\n","\n","df = df.withColumn('days_difference', datediff(df.parsed_date_mdy,df.parsed_date_iso))\n","df.select('parsed_date_mdy','parsed_date_iso','days_difference').show(truncate = False)"]},{"cell_type":"code","execution_count":58,"id":"26820f40","metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["25/07/10 17:20:23 WARN ApplicationMaster: Reporter thread fails 1 time(s) in a row.\n","java.io.InterruptedIOException: Call interrupted\n","\tat org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1557) ~[hadoop-client-api-3.3.6.jar:?]\n","\tat org.apache.hadoop.ipc.Client.call(Client.java:1509) ~[hadoop-client-api-3.3.6.jar:?]\n","\tat org.apache.hadoop.ipc.Client.call(Client.java:1406) ~[hadoop-client-api-3.3.6.jar:?]\n","\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:258) ~[hadoop-client-api-3.3.6.jar:?]\n","\tat org.apache.hadoop.ipc.ProtobufRpcEngine2$Invoker.invoke(ProtobufRpcEngine2.java:139) ~[hadoop-client-api-3.3.6.jar:?]\n","\tat com.sun.proxy.$Proxy40.allocate(Unknown Source) ~[?:?]\n","\tat org.apache.hadoop.yarn.api.impl.pb.client.ApplicationMasterProtocolPBClientImpl.allocate(ApplicationMasterProtocolPBClientImpl.java:78) ~[hadoop-client-api-3.3.6.jar:?]\n","\tat jdk.internal.reflect.GeneratedMethodAccessor34.invoke(Unknown Source) ~[?:?]\n","\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]\n","\tat java.base/java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]\n","\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:433) ~[hadoop-client-api-3.3.6.jar:?]\n","\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeMethod(RetryInvocationHandler.java:166) ~[hadoop-client-api-3.3.6.jar:?]\n","\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invoke(RetryInvocationHandler.java:158) ~[hadoop-client-api-3.3.6.jar:?]\n","\tat org.apache.hadoop.io.retry.RetryInvocationHandler$Call.invokeOnce(RetryInvocationHandler.java:96) ~[hadoop-client-api-3.3.6.jar:?]\n","\tat org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:362) ~[hadoop-client-api-3.3.6.jar:?]\n","\tat com.sun.proxy.$Proxy41.allocate(Unknown Source) ~[?:?]\n","\tat org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl.allocate(AMRMClientImpl.java:325) ~[hadoop-client-api-3.3.6.jar:?]\n","\tat org.apache.spark.deploy.yarn.YarnAllocator.allocateResources(YarnAllocator.scala:426) ~[spark-yarn_2.12-3.5.3.jar:3.5.3]\n","\tat org.apache.spark.deploy.yarn.ApplicationMaster.org$apache$spark$deploy$yarn$ApplicationMaster$$allocationThreadImpl(ApplicationMaster.scala:578) [spark-yarn_2.12-3.5.3.jar:3.5.3]\n","\tat org.apache.spark.deploy.yarn.ApplicationMaster$$anon$1.run(ApplicationMaster.scala:648) [spark-yarn_2.12-3.5.3.jar:3.5.3]\n"]}],"source":["spark.stop()"]}],"metadata":{"kernelspec":{"display_name":"PySpark","language":"python","name":"pyspark"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.8"}},"nbformat":4,"nbformat_minor":5}